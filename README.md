# RAG-агент для поиска мишеней при болезни Альцгеймера

Прототип RAG (Retrieval-Augmented Generation) системы для помощи исследователям в поиске новых потенциальных мишеней для разработки лекарств от болезни Альцгеймера.

## Содержание

- [Описание проекта](#описание-проекта)
- [Структура проекта](#структура-проекта)
- [Этапы реализации](#этапы-реализации)
  - [Этап 1: Сбор базы данных](#этап-1-сбор-базы-данных)
  - [Этап 2: Реализация RAG системы](#этап-2-реализация-rag-системы)
  - [Этап 3: Интерфейс](#этап-3-интерфейс)
- [Выбранные модели](#выбранные-модели)
- [Расширение на другие модальности данных](#расширение-на-другие-модальности-данных)
- [Установка и запуск](#установка-и-запуск)
- [Примеры использования](#примеры-использования)

## Описание проекта

Система позволяет исследователям задавать вопросы на английском языке о потенциальных мишенях для лечения болезни Альцгеймера и получать ответы на основе анализа научных статей из открытых источников. Система автоматически извлекает релевантные фрагменты из базы знаний и генерирует ответы с указанием источников.

### Основные возможности:

- Поиск информации о мишенях при болезни Альцгеймера
- Сайдбар с цитируемыми документами
- Цитирование источников с указанием DOI/URL
- Интерактивный чат с сохранением контекста диалога

## Структура проекта

```
.
├── db_collecting/              # Этап 1: Сбор и обработка данных
│   ├── DB_collecting.ipynb     # Ноутбук для сбора статей
│   ├── articles_df.csv         # Таблица со статьями и метаданными
│   ├── long_bd_df.csv          # Длинный формат данных (abstract/intro/results)
│   ├── chroma_artilcles/       # Векторная база данных ChromaDB
│   ├── db/                     # PDF файлы статей
│   └── requirements_db_collecting.txt
│
├── rag/                        # Этап 2: RAG система
│   ├── rag_creating.ipynb      # Ноутбук создания RAG pipeline
│   ├── rag.py                  # Функции RAG системы
│   └── eval_df.csv             # Результаты оценки качества
│
├── static/                     # Статические файлы для интерфейса
│   └── files/                  # PDF файлы для отображения
│
├── main.py                     # Streamlit интерфейс
├── testing_rag_functions.ipynb # Тестирование функций
└── README.md                   # Документация
```

## Этапы реализации

### Этап 1: Сбор базы данных

#### 1.1 Сбор статей

**Источники данных:**
- OpenAlex API для поиска статей
- Фильтры: открытый доступ (is_oa:true), тип "article", период 2021-2026
- Поисковые запросы:
  - "Alzheimer's disease targets"
  - "Alzheimer therapeutic targets"
  - "Alzheimer drug targets"

**Результат:** Собрано 29 статей (после фильтрации недоступных и неанглоязычных)

#### 1.2 Извлечение и очистка текста

**Процесс:**
1. Скачивание PDF файлов статей
2. Извлечение текста с помощью `pypdf`
3. Извлечение разделов (Abstract, Introduction, Results) с помощью LLM:
   - **Локальная модель:** Qwen2.5:7b-instruct (для создания саммари)
   - **API модель:** Gemini 2.5 Flash (для точного извлечения разделов)

**Структура данных:**
- Каждая статья разбита на 3 типа текстов: `abstract`, `introduction`, `result`
- Итого: 87 текстовых фрагментов (29 статей × 3 раздела)

#### 1.3 Эксплораторный анализ

**Проведенный анализ:**
- Статистика длины текстов по разделам:
  - Abstract: ~150-200 слов
  - Introduction: ~620 слов (в среднем)
  - Results: ~2000+ слов (в среднем)
- Анализ частотности n-грамм (2-4 граммы)
- Выявление и удаление мусорных фраз ("et al", "supporting information", "shown figure")

**Выводы:**
- Тексты различаются по длине, требуется чанкинг
- Оптимальный размер чанка: 300-500 токенов с перекрытием ~50 токенов

#### 1.4 Подготовка данных для моделирования

**Шаги:**
1. Очистка текстов от мусорных фраз
2. Разбиение на чанки с помощью `RecursiveCharacterTextSplitter`:
   - `chunk_size=450`
   - `chunk_overlap=50`
3. Создание векторной базы данных ChromaDB:
   - Модель эмбеддингов: `sentence-transformers/all-mpnet-base-v2`
   - Метаданные: title, year, link, type, file

**Результат:** Векторная база данных с 2503 чанками документов

### Этап 2: Реализация RAG системы

#### 2.1 Архитектура системы

Система состоит из нескольких компонентов:

1. **Retriever (извлечение документов)**
   - Векторная база: ChromaDB
   - Эмбеддинги: `sentence-transformers/all-mpnet-base-v2`
   - Стратегия поиска: MMR (Maximum Marginal Relevance)
   - Параметры:
     - `k=5` - количество возвращаемых документов
     - `fetch_k=35` - размер кандидатного пула
     - `lambda_mult=0.3` - баланс между релевантностью и разнообразием

2. **Question Identification Chain**
   - Преобразует вопросы с учетом контекста диалога в standalone вопросы
   - Модель: `google/gemma-3-27b-it:free`
   - Temperature: 0.2
   - Max tokens: 2000

3. **Answer Generation Chain**
   - Генерирует ответ на основе извлеченных документов
   - Модель: `google/gemma-3-27b-it:free`
   - Temperature: 0.2
   - Max tokens: 2000

4. **Answer Structurization Chain**
   - Форматирует ответ в JSON с извлечением названий файлов для источников
   - Модель: `meta-llama/llama-3.3-70b-instruct:free`
   - Temperature: 0 (детерминированная структуризация)

#### 2.2 Промпты

**Question Identification:**
```
Given a chat history and the latest user question which might reference context 
in the chat history, formulate a standalone question which can be understood 
without the chat history.
```

**Answer Generation:**
```
You are a scientific assistant specializing in Alzheimer's disease research. 
Answer questions based ONLY on the provided context from scientific articles.
STRICT RULES:
1. Answer ONLY using information explicitly stated in the context
2. If insufficient information, say so explicitly
3. Never use external knowledge
4. Always cite sources with titles and DOI/URLs
```

**Answer Structurization:**
```
Format the answer as JSON with:
- "message": The answer text
- "sources": List of objects with "title" and "file" keys
```

#### 2.3 Оценка качества

**Метрики:**
- **Faithfulness** (достоверность): отсутствие галлюцинаций, соответствие контексту
- **Answer Relevance** (релевантность ответа): насколько ответ соответствует вопросу
- **Context Precision** (точность контекста): релевантность извлеченных документов

**Методология:**
- Создано 10 тестовых вопросов на основе случайных документов
- Оценка с помощью LLM (Llama 3.3 70B) по шкале 1-3 для каждой метрики
- Итоговая оценка: среднее значение суммы баллов (максимум 9)

**Результаты:**
- **Итоговая оценка: 7.9 из 9** (хорошая система)
- Система строго следует контексту, отвечает на вопросы, но иногда извлекает документы с шумом
- Все исходные статьи, на основе которых сгенерированы вопросы, попадали в список извлеченных документов

### Этап 3: Интерфейс

#### 3.1 Streamlit приложение

**Функциональность:**
- Интерактивный чат с историей диалога
- Отображение найденных источников в боковой панели
- Ссылки на PDF файлы статей
- Кнопка очистки чата

**Особенности:**
- Кэширование RAG системы для быстрой загрузки
- Обработка ошибок
- Адаптивный интерфейс

#### 3.2 Запуск интерфейса

```bash
streamlit run main.py
```

## Выбранные модели

### Модели эмбеддингов

**`sentence-transformers/all-mpnet-base-v2`**

**Почему выбрана:**
- Баланс между качеством и скоростью
- Поддержка контекста до 512 токенов
- Проверенная модель для RAG систем

### Модели генерации

**1. `google/gemma-3-27b-it:free` (OpenRouter)**

**Использование:**
- Question identification
- Answer generation

**Почему выбрана:**
- Бесплатный доступ через OpenRouter
- Хорошее качество генерации
- Доступна из России

**2. `meta-llama/llama-3.3-70b-instruct:free` (OpenRouter)**

**Использование:**
- Answer structurization
- Evaluation

**Почему выбрана:**
- Отличное следование инструкциям
- Поддержка structured output (JSON)
- Бесплатный доступ
- Высокое качество для задач структурирования

### Модели для обработки данных

**1. `qwen2.5:7b-instruct` (локальная, Ollama)**

**Использование:**
- Создание саммари статей на этапе предобработки

**Почему выбрана:**
- Локальное выполнение (быстро, без API лимитов)
- Второе место на лидерборде Hugging Face для моделей <8B параметров
- Большое контекстное окно (в 3 раза больше чем у лидера)
- Неплохое качество для задач извлечения информации

**2. `gemini-2.5-flash` (Google API)**

**Использование:**
- Точное извлечение разделов статей (Abstract, Introduction, Results)

**Почему выбрана:**
- Высокое качество следования инструкциям
- Поддержка structured output
- Быстрая обработка
- Хорошая работа с длинными текстами

## Расширение на другие модальности данных

### Универсальность базы знаний
Архитектура агента не привязана жестко к теме болезни Альцгеймера. Систему можно легко масштабировать на другие научные области, просто добавив в базу знаний соответствующие статьи. Это позволяет использовать агента как исследовательского ассистента для различных доменных областей.

### Изображения
Изображения, как снимки МРТ или гистологические изображения, можно обрабатывать с помощью соответствующих моделей VLM. Так же, как и при работе с текстом, векторные представления изображений можно хранить в базе (снимки МРТ с описаниями либо картинки и графики из статей), чтобы на основе контекста агент выдавал описание подаваемого ему изображения. А можно реализовать систему, которая, наоборот, выдает изображения на основе описания пользователя.

### Агенты для анализа мозговой активности (ЭЭГ)
Особый интерес для меня представляет исследование методов обработки сигналов мозговой активности с помощью ассистентов. Было бы интересно реализовать мультимодальную систему с использованием LLM и нейросетей для интерпретации данных ЭЭГ, например. Моя магистерская диссертация была посвящена классификации ЭЭГ-сигналов, поэтому есть определенный опыт в данной области. В рамках работы разрабатывался подход к распознаванию музыкальной композиции, которую слушал человек, по записи его мозговой активности.

Подробнее с этим проектом можно ознакомиться в репозитории: [ClassMusEEG](https://github.com/AskerNagoev/ClassMusEEG).

## Установка и запуск

### Требования

- Python 3.8+
- API ключи:
  - `OPENROUTER_API_KEY` (для доступа к моделям через OpenRouter)

### Установка зависимостей

1. **Для сбора данных:**
```bash
cd db_collecting
pip install -r requirements_db_collecting.txt
```

2. **Для RAG системы и интерфейса:**
```bash
pip install -r  requirements.txt
```

### Настройка

Удалите из названия файла `.env example` в корне проекта слово example и впишите туда API-токен:
```
OPENROUTER_API_KEY=your_openrouter_api_key_here
```

### Запуск интерфейса

```bash
streamlit run main.py
```

Интерфейс откроется в браузере.

## Примеры использования

**Вопрос:**
```
What are potential targets for Alzheimer's disease treatment?
```

**Ожидаемый ответ:**
Система перечислит различные терапевтические мишени, упомянутые в статьях, с указанием источников.

## Метрики качества

- **Faithfulness:** 2.6/3 (высокая достоверность)
- **Answer Relevance:** 2.7/3 (отличная релевантность)
- **Context Precision:** 2.6/3 (хорошая точность контекста)
- **Общая оценка:** 7.9/9 (хорошая система)

## Технические детали

### Используемые библиотеки

- **LangChain** - для построения RAG pipeline
- **ChromaDB** - векторная база данных
- **Streamlit** - веб-интерфейс
- **sentence-transformers** - модели эмбеддингов
- **OpenRouter API** - доступ к LLM моделям

### Производительность

- Время ответа: ~15-30 секунд (зависит от API)
- Размер базы данных: ~2000+ чанков документов
- Поддержка контекста диалога: последние 5 сообшений (вопрос и 2 от пользователя + 2 от агента)

## Лицензия

Проект под лицензией MIT. Подробнее см. файл [LICENSE](LICENSE).

## Авторы

@AskerNagoev - тестовое задание для стажировки 2026.

---

**Примечание:** Система использует бесплатные API с ограничениями (20 запросов/минуту, 50/день для OpenRouter). Для production использования рекомендуется использовать платные API или локальные модели.
